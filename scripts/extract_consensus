#!/usr/bin/env python3

'''
input:  alignment file as BAM file
output: consensus sequences including either the majority base or the ambiguous
        bases as FASTA files
'''

import pysam
import argparse
import os
import numpy as np
from Bio import SeqIO
from Bio.SeqRecord import SeqRecord
from Bio.Seq import Seq
from smallgenomeutilities.__checkPath__ import CheckPath

def parse_args():
    """ Set up the parsing of command-line arguments """
    parser = argparse.ArgumentParser(
            description="Script to construct consensus sequences",
            formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    requiredNamed = parser.add_argument_group('required named arguments')
    requiredNamed.add_argument("-i", required=True, metavar='BAM',
                               dest='bamfile', help="Input BAM file")
    parser.add_argument("-f", required=False, metavar='FASTA', dest='reference',
                        type=str,
                        help="Fasta file containing the reference sequence")
    parser.add_argument("-r", required=False, default=None, metavar='BED',
                        dest='region', type=str,
                        help="Region of interested in BED format, e.g. HXB2:2253-3869. Loci are interpreted using 0-based indexing, and a half-open interval is used, i.e, [start:end)")
    parser.add_argument("-c", required=False, default=50, metavar='INT',
                        dest='min_coverage', type=int,
                        help="Minimum read depth for reporting variants per locus")
    parser.add_argument("-q", required=False, default=15, metavar='INT',
                        dest='qual_thrd', type=int,
                        help="Minimum phred quality score a base has to reach to be counted")
    parser.add_argument("-a", required=False, default=0.05, metavar='FLOAT',
                        dest='min_freq', type=float, help="Minimum frequency for an ambiguous nucleotide")
    parser.add_argument("-n", required=False, default=None, metavar='INT',
                        dest='n_threshold', type=int,
                        help="Read count below which ambiguous base 'n' is reported")
    parser.add_argument("-N", required=False, default="CONSENSUS", type=str,
                        metavar='STR', dest="sampleID",
                        help="Patient/sample identifier")
    parser.add_argument("-o", required=False, default=os.getcwd(),
                        action=CheckPath, metavar='PATH', dest='outdir',
                        help="Output directory")

    return parser.parse_args()



def first_base_count(seq_count_tuple):
    '''Return the counts of unique first bases of an alignment column sequence count tuple possibly containing indels.

    Parameters:
        seq_count_tuple: tuple of the form ([bases/indels], [counts])
            The tuple contains a list of bases and (possibly) indels at this alignment column,
            and a list of the respective counts, as returned by np.unique(x, return_counts=True),
            where x is a column of a AlignmentFile.pileup()

    Returns:
        a tuple of the form ([bases], [counts]), where [bases] is a list of bases including the first bases
        of eventual indels and [counts] are their respective counts
    '''
    first_bases = [u[0] for u in seq_count_tuple[0]]
    first_bases_uniques = np.unique(first_bases, return_inverse=True)
    counts_collapsed = np.zeros_like(first_bases_uniques[0], dtype="int")
    for i in range(len(first_bases_uniques[1])):
        counts_collapsed[first_bases_uniques[1][i]] += seq_count_tuple[1][i]

    return (first_bases_uniques[0], counts_collapsed)

def build_insert_matrix(seq_count_tuple):
    '''Build an insert matrix from a sequence count tuple.

    Parameters:
        seq_count_tuple: tuple of the form ([bases/indels], [counts])
            The tuple contains a list of bases and (possibly) indels at this alignment column,
            and a list of the respective counts, as returned by np.unique(x, return_counts=True),
            where x is a column of a AlignmentFile.pileup()

    Returns:
        insert_matrix: np.array [n_inserts, max_insert_length]
            The insert matrix contains one row per insert and as many column as there are bases in the largest insert.
            The shorter inserts are right-padded with '*'.
    '''
    insert_matrix = []
    length = 0
    #make list of insertions at that position
    for j in range(len(seq_count_tuple[0])):
        if (len(seq_count_tuple[0][j])>2) and (seq_count_tuple[0][j][1] == '+'):
            # get number after + (this number can be 3,2 or 1 digit long)
            # this corresponds to the lenght of the insertion
            if (len(seq_count_tuple[0][j])>4) and (seq_count_tuple[0][j][4].isdigit()):
                curr_insert_len = int(seq_count_tuple[0][j][2:5])
                idx=5
            elif (len(seq_count_tuple[0][j])>3) and (seq_count_tuple[0][j][3].isdigit()):
                curr_insert_len = int(seq_count_tuple[0][j][2:4])
                idx=4
            elif seq_count_tuple[0][j][2].isdigit():
                curr_insert_len = int(seq_count_tuple[0][j][2:3])
                idx=3
            # find index where alphabet starts
            for n in range(seq_count_tuple[1][j]):
                insert_matrix.append(list(seq_count_tuple[0][j][idx:]))
            if length < curr_insert_len:
                length = curr_insert_len
    #right pad shorter insertions with "-"
    for m in range(len(insert_matrix)):
        while len(insert_matrix[m]) < length:
            insert_matrix[m].append('*') #replace here '*'->'-' if we arent supposed to count it as deletion
    return np.array(insert_matrix)

def collapse_insert_matrix(insert_matrix, authorised_alphabet=['A', 'T', 'G', 'C']):
    '''Function to build local consensus from insert matrix.

    Parameters:
        insert_matrix: np.array [n_inserts, max_insert_length]
            As returned by build_insert_matrix()
        authorised_alphabet: list of characters
            Characters in the insert_matrix that do not belong to authorised_alphabet will not be counted when
            building the local consensus.

    Returns:
        seq_out: list of characters
            A local consensus sequence built from the most frequent bases of each column of the consensus matrix.

    '''
    seq_out = []
    print('insert_matrix.shape', insert_matrix.shape)
    print('insert_matrix.shape[1]', insert_matrix.shape[1])
    for c in range(insert_matrix.shape[1]):
        #filter matrix column keeping only elements of authorised alphabet
        matrix_column = insert_matrix[:,c][np.in1d(insert_matrix[:,c], authorised_alphabet)]
        if matrix_column.size > 0: # i.e. if we havent filtered out the whole column
            #keep most frequent
            unique = np.unique(matrix_column, return_counts=True)
            max_index = np.argmax(unique[1])
            seq_out.append(unique[0][max_index])
    return seq_out

def check_coverage(first_base, min_coverage, n_threshold, curr_pos, reference = None,
                   reference_name = None, start=None, end=None):
    '''
    curr_pos: current position in the reference sequence
    If read depth is lower than min_coverage lowercase letters are reported
    Read count below n_threshold are reported as ambiguous base 'n'.
    If there is no n_threshold, base with zero count output 'n' or if reference available take value of reference.
    '''
    max_index = np.argmax(first_base[1])
    if np.sum(first_base[1])< min_coverage:
        # if read depth bigger than n_thres but still lower than min_coverage
        # cast lowercase
        first_base[0][max_index]= np.char.lower(first_base[0][max_index])

    if (n_threshold is None):
        if (np.sum(first_base[1])==0):
            # if there are is no n_thres but we have zero counts at position
            # return 'n' or reference[curr_pos]
            if reference is None:
                first_base[0][max_index] = 'n'
            else:
                reference = pysam.FastaFile(reference)
                assert reference.references[0] == reference_name, (
                    "the name of the genomic region and the reference differ")
                reference = reference.fetch(
                    reference=reference_name, start=start, end=end).lower()
                first_base[0][max_index] = reference[curr_pos]

    elif np.sum(first_base[1]) < n_threshold:
        first_base[0][max_index] = 'n'

    return first_base

def ambiguous_bases(first_base, min_freq, majority=None, deletions=False):
    '''
    To report ambiguous bases, every base with a relative frequency greater or
    equal to min_freq is accounted for. But at least two reads should support
    that base.
    '''
    coverage = np.sum(first_base[1])
    min_count = min_freq*coverage
    min_count = max(2, min_count)
    idx= np.where(first_base[1]>=min_count)

    #TODO: what to do if len(idx) is zero, read counts are insufficient

    # only one base has relative frequency >= min_count
    if len(idx)==1:
        ambiguous_base= first_base[0][idx]
        return ambiguous_base
    # IUPAC nucleotide code form
    # https://www.bioinformatics.org/sms/iupac.html
    if set(first_base[0][idx])==set(['A','G']):
        ambiguous_base = 'R'
        return ambiguous_base
    if set(first_base[0][idx])==set(['C','T']):
        ambiguous_base = 'Y'
        return ambiguous_base
    if set(first_base[0][idx])==set(['G','C']):
        ambiguous_base = 'S'
        return ambiguous_base
    if set(first_base[0][idx])==set(['A','T']):
        ambiguous_base = 'W'
        return ambiguous_base
    if set(first_base[0][idx])==set(['T','G']):
        ambiguous_base = 'K'
        return ambiguous_base
    if set(first_base[0][idx])==set(['A','C']):
        ambiguous_base = 'M'
        return ambiguous_base
    if set(first_base[0][idx])==set(['G','C','T']):
        ambiguous_base = 'B'
        return ambiguous_base
    if set(first_base[0][idx])==set(['G','A','T']):
        ambiguous_base = 'D'
        return ambiguous_base
    if set(first_base[0][idx])==set(['C','A','T']):
        ambiguous_base = 'H'
        return ambiguous_base
    if set(first_base[0][idx])==set(['G','A','C']):
        ambiguous_base = 'V'
        return ambiguous_base
    if set(first_base[0][idx])==set(['G','A','C','T']):
        ambiguous_base = 'N'
        return ambiguous_base
    else:
        print('Error in ambiguous_bases function')




def main():
    # define alphabets for filtering sequences
    alphabet = np.array(['A', 'T', 'G', 'C'])
    alphabet_deletions = np.array(['A', 'T', 'G', 'C', '*'])
    alphabet_ambiguous = np.array(['n', 'T', 'G', 'K', 'C', 'Y', 'S', 'B', 'A', 'W', 'R', 'D', 'M', 'H', 'V', 'N'])
    alphabet_ambiguous_deletions = np.array(['n', 'T', 'G', 'K', 'C', 'Y', 'S', 'B', 'A', 'W', 'R', 'D', 'M', 'H', 'V', 'N', '*'])

    # parse arguments
    args = parse_args()

    reference_name = None
    if args.region is not None:
        aux = args.region.split(":")
        reference_name = aux[0]
        sampleID = ':'.join((args.sampleID, aux[1]))
        aux = aux[1].split('-')
        start = int(aux[0])
        end = int(aux[1])
    else:
        start = None
        end = None
        sampleID = args.sampleID


    # 1. Load BAM file and get base/count tuples per loci:
    quer_sequences_count = []
    reference_pos = []
    with pysam.AlignmentFile(args.bamfile, 'rb') as alnfile:
        if reference_name is None:
            reference_name = alnfile.references[0]
        # make list of ([bases], [counts]) tuples at each pileup column
        pileup = alnfile.pileup(
            contig=reference_name, start=start, stop=end,
            min_base_quality=args.qual_thrd)
        for pos in pileup:
            pileup_column = pos.get_query_sequences(add_indels=True)
            pileup_column = [item.upper() for item in pileup_column] # Note: time expensive
            count_tuple = np.unique(pileup_column, return_counts=True)
            reference_pos.append(pos.reference_pos)
            quer_sequences_count.append(count_tuple)

    # 2. Build consensus sequence

    # lists to contain consensus sequences
    cons_majority = [] # holds consensus sequence without deletions and without ambiguous bases
    cons_majority_deletions = [] # holds consensus sequence with deletions and without ambiguous bases
    cons_majority_ambiguous = [] # holds consensus sequence without deletions and with ambiguous bases
    cons_majority_ambiguous_deletions = [] # holds consensus sequence with deletions and with ambiguous bases

    # iterate through the alignment columns counts and make local consensus for each output type
    for idx, column in enumerate(quer_sequences_count):
        # get the counts for only the first base
        first_base_ambiguous_deletions = first_base_count(column)
        # build the insert matrix
        insert_matrix = build_insert_matrix(column)

        # 2.1 make consensus at column without deletions and without ambiguous bases
        index = np.in1d(first_base_ambiguous_deletions[0], alphabet)
        first_base = (first_base_ambiguous_deletions[0][index],
                      first_base_ambiguous_deletions[1][index])
        if first_base[0].size > 0: # i.e. if we havent filtered out the whole column
            max_index = np.argmax(first_base[1])
            first_base = check_coverage(first_base, args.min_coverage,
                                        args.n_threshold,reference_pos[idx], reference=args.reference,
                                        reference_name=reference_name, start=start,
                                        end=end)
            cons_majority.append(first_base[0][max_index])
        else: cons_majority.append('N') # if we filtered out the whole column we use 'N'
        # add insertions
        if insert_matrix.size > 0:
            print('column ', column)
            print('insert_matrix', insert_matrix)
            cons_majority.extend(collapse_insert_matrix(insert_matrix, alphabet))

        # 2.2 make consensus at column with deletions and without ambiguous bases
        index_deletions = np.in1d(first_base_ambiguous_deletions[0], alphabet_deletions)
        first_base_deletions = (first_base_ambiguous_deletions[0][index_deletions],
                                first_base_ambiguous_deletions[1][index_deletions])
        if first_base_deletions[0].size > 0: # i.e. if we havent filtered out the whole column
            max_index_deletions = np.argmax(first_base_deletions[1])
            first_base_deletions = check_coverage(first_base_deletions,args.min_coverage,
                                                  args.n_threshold,reference_pos[idx],
                                                  reference=args.reference,
                                                  reference_name=reference_name, start=start,
                                                  end=end)
            cons_majority_deletions.append(first_base_deletions[0][max_index_deletions])
        else: cons_majority.append('N') # if we filtered out the whole column we use 'N'
        # add insertions
        if insert_matrix.size > 0:
            cons_majority_deletions.extend(collapse_insert_matrix(insert_matrix, alphabet_deletions))

        # 2.3 make consensus at column without deletions and with ambiguous bases
        index_ambiguous = np.in1d(first_base_ambiguous_deletions[0], alphabet_ambiguous)
        first_base_ambiguous = (first_base_ambiguous_deletions[0][index_ambiguous],
                                first_base_ambiguous_deletions[1][index_ambiguous])

        if first_base_ambiguous[0].size > 0: # i.e. if we havent filtered out the whole column
            max_index_ambiguous = np.argmax(first_base_ambiguous[1])
            first_base_ambiguous = check_coverage(first_base_ambiguous, args.min_coverage,
                                                  args.n_threshold,reference_pos[idx],
                                                  reference=args.reference,
                                                  reference_name=reference_name, start=start,
                                                  end=end)
            #ambiguous_base = ambiguous_bases(first_base_ambiguous, 0.05, majority=None, deletions=False)
            #cons_majority_ambiguous.append(ambiguous_base)
            cons_majority_ambiguous.append(first_base_ambiguous[0][max_index_ambiguous])
        else: cons_majority.append('N') # if we filtered out the whole column we use 'N'
        # add insertions
        if insert_matrix.size > 0:
            cons_majority_ambiguous.extend(collapse_insert_matrix(insert_matrix, alphabet_ambiguous))

        # 2.4 make consensus at column with deletions and with ambiguous bases
        index_ambiguous_deletions = np.in1d(first_base_ambiguous_deletions[0], alphabet_ambiguous_deletions)
        first_base_ambiguous_deletions = (first_base_ambiguous_deletions[0][index_ambiguous_deletions],
                                          first_base_ambiguous_deletions[1][index_ambiguous_deletions])

        if first_base_ambiguous[0].size > 0: # i.e. if we havent filtered out the whole column
            max_index_ambiguous_deletions = np.argmax(first_base_ambiguous_deletions[1])
            first_base_ambiguous_deletions= check_coverage(first_base_ambiguous_deletions,args.min_coverage,
                                                           args.n_threshold,reference_pos[idx],
                                                           reference=args.reference,
                                                           reference_name=reference_name, start=start,
                                                           end=end)
            cons_majority_ambiguous_deletions.append(first_base_ambiguous_deletions[0][max_index_ambiguous_deletions])
        else: cons_majority.append('N') # if we filtered out the whole column we use 'N'
        # add insertions
        if insert_matrix.size > 0:
            cons_majority_ambiguous_deletions.extend(collapse_insert_matrix(insert_matrix, alphabet_ambiguous_deletions))

    # 3. Write to output
    cons_majority = SeqRecord(
        Seq(''.join(cons_majority)), id=sampleID,
        description="| Majority-vote rule")

    cons_majority_dels = SeqRecord(
        Seq(''.join(cons_majority_deletions)), id=sampleID,
        description="| Majority-vote rule")

    cons_ambig = SeqRecord(
        Seq(''.join(cons_majority_ambiguous)), id=sampleID,
        description="| Ambiguous bases")


    cons_ambig_dels = SeqRecord(
        Seq(''.join(cons_majority_ambiguous_deletions)), id=sampleID,
        description="| Ambiguous bases")

    with open(os.path.join(args.outdir, "ref_majority.fasta"), "w") as outfile:
        SeqIO.write(cons_majority, outfile, "fasta")

    with open(os.path.join(args.outdir, "ref_ambig.fasta"), "w") as outfile:
        SeqIO.write(cons_ambig, outfile, "fasta")

    with open(os.path.join(args.outdir, "ref_majority_dels.fasta"),
              "w") as outfile:
        SeqIO.write(cons_majority_dels, outfile, "fasta")

    with open(os.path.join(args.outdir, "ref_ambig_dels.fasta"),
              "w") as outfile:
        SeqIO.write(cons_ambig_dels, outfile, "fasta")


if __name__ == '__main__':
    main()
